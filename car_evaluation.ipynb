{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, value=None, children=None, label=None):\n",
    "        # Initializing a Node object with optional parameters:\n",
    "        # - feature: Storing the feature used for splitting in this node.\n",
    "        # - value: Storing the specific value used for splitting in this node (for categorical features).\n",
    "        # - children: A dictionary to store child nodes (subtrees).\n",
    "        # - label: Storing the predicted label for leaf nodes.\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.children = children if children is not None else {}\n",
    "        self.label = label\n",
    "class ID3DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        # Initializing an ID3 Decision Tree Classifier with an optional maximum depth parameter.\n",
    "        # - max_depth: Limiting the depth of the decision tree.\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None  # Initializing the decision tree as None.\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Fitting the decision tree classifier to the provided data.\n",
    "        # - X: The feature matrix.\n",
    "        # - y: The target labels.\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "        # Building the decision tree recursively starting with depth 0.\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        # Attempting to build a decision tree node recursively:\n",
    "        # - X: The feature matrix for the current node.\n",
    "        # - y: The target labels for the current node.\n",
    "        # - depth: The current depth in the tree.\n",
    "        num_samples, num_features = X.shape\n",
    "        unique_classes, counts = np.unique(y, return_counts=True)\n",
    "        majority_class = unique_classes[np.argmax(counts)]\n",
    "        # Finding the majority class among the target labels.\n",
    "        # Attempting to stop the recursion:\n",
    "        if len(unique_classes) == 1 or (self.max_depth is not None and depth == self.max_depth):\n",
    "            return Node(label=majority_class)\n",
    "        # If all labels are the same or the maximum depth is reached, create a leaf node with the majority class.\n",
    "        best_feature, best_value, is_categorical = self._find_best_split(X, y)\n",
    "        if best_feature is None:\n",
    "            return Node(label=majority_class)\n",
    "        # Finding the best feature and value to split the data.\n",
    "        children = {}\n",
    "        if is_categorical:\n",
    "            unique_values = np.unique(X[:, best_feature])\n",
    "            for value in unique_values:\n",
    "                child_X, child_y = self._split_data_categorical(X, y, best_feature, value)\n",
    "                children[value] = self._build_tree(child_X, child_y, depth + 1)\n",
    "        else:\n",
    "            child_X_left, child_y_left, child_X_right, child_y_right = self._split_data_numerical(X, y, best_feature, best_value)\n",
    "            children['<= ' + str(best_value)] = self._build_tree(child_X_left, child_y_left, depth + 1)\n",
    "            children['> ' + str(best_value)] = self._build_tree(child_X_right, child_y_right, depth + 1)\n",
    "        # Recursively building child nodes for categorical and numerical features.\n",
    "        return Node(feature=best_feature, value=best_value, children=children)\n",
    "    def _find_best_split(self, X, y):\n",
    "        # Attempting to find the best feature and value to split the data:\n",
    "        # - X: The feature matrix.\n",
    "        # - y: The target labels.\n",
    "        num_samples, num_features = X.shape\n",
    "        entropy = self._calculate_entropy(y)\n",
    "        best_information_gain = -1\n",
    "        best_feature = None\n",
    "        best_value = None\n",
    "        is_categorical = False\n",
    "        for feature in range(num_features):\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            if len(unique_values) <= 1:\n",
    "                continue\n",
    "            if all(isinstance(value, (int, float)) for value in unique_values):\n",
    "                # Trying to find the best split for numerical features:\n",
    "                for value in unique_values:\n",
    "                    child_X_left, child_y_left, child_X_right, child_y_right = self._split_data_numerical(X, y, feature, value)\n",
    "                    information_gain = entropy - (len(child_y_left) / num_samples) * self._calculate_entropy(child_y_left) - (len(child_y_right) / num_samples) * self._calculate_entropy(child_y_right)\n",
    "                    if information_gain > best_information_gain:\n",
    "                        best_information_gain = information_gain\n",
    "                        best_feature = feature\n",
    "                        best_value = value\n",
    "                        is_categorical = False\n",
    "            else:\n",
    "                # Trying to find the best split for categorical features:\n",
    "                for value in unique_values:\n",
    "                    child_X, child_y = self._split_data_categorical(X, y, feature, value)\n",
    "                    information_gain = entropy - (len(child_y) / num_samples) * self._calculate_entropy(child_y)\n",
    "                    if information_gain > best_information_gain:\n",
    "                        best_information_gain = information_gain\n",
    "                        best_feature = feature\n",
    "                        best_value = value\n",
    "                        is_categorical = True\n",
    "\n",
    "        return best_feature, best_value, is_categorical\n",
    "\n",
    "    def _calculate_entropy(self, y):\n",
    "        # Calculating the entropy of a set of target labels:\n",
    "        # - y: The target labels.\n",
    "\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "        return entropy\n",
    "    def _split_data_numerical(self, X, y, feature, value):\n",
    "        # Attempting to split data for numerical features:\n",
    "        # - X: The feature matrix.\n",
    "        # - y: The target labels.\n",
    "        # - feature: The feature to split.\n",
    "        # - value: The value to split at.\n",
    "        left_mask = X[:, feature] <= value\n",
    "        right_mask = X[:, feature] > value\n",
    "        return X[left_mask], y[left_mask], X[right_mask], y[right_mask]\n",
    "    def _split_data_categorical(self, X, y, feature, value):\n",
    "        # Attempting to split data for categorical features:\n",
    "        # - X: The feature matrix.\n",
    "        # - y: The target labels.\n",
    "        # - feature: The feature to split.\n",
    "        # - value: The value to split at.\n",
    "        mask = X[:, feature] == value\n",
    "        return X[mask], y[mask]\n",
    "    def predict(self, X):\n",
    "        # Predicting labels for a set of samples:\n",
    "        # - X: The feature matrix for prediction.\n",
    "        return np.array([self._predict_sample(x) for x in X])\n",
    "    def _predict_sample(self, x):\n",
    "        # Attempting to predict the label for a single sample:\n",
    "        # - x: The feature vector for prediction.\n",
    "        node = self.tree\n",
    "        while node.children:\n",
    "            feature_value = x[node.feature]\n",
    "            if feature_value in node.children:\n",
    "                node = node.children[feature_value]\n",
    "            else:\n",
    "                break\n",
    "        return node.label if node.label is not None else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory:  C:\\Users\\User\\Downloads\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to which you want to change the directory\n",
    "path = r\"C:\\Users\\User\\Downloads\"\n",
    "\n",
    "# Change the current working directory to the specified path\n",
    "os.chdir(path)\n",
    "\n",
    "# You can print the current working directory to confirm the change\n",
    "print(\"Current Working Directory: \", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1, Accuracy: 0.6791907514450867\n",
      "Max Depth: 2, Accuracy: 0.7658959537572254\n",
      "Max Depth: 3, Accuracy: 0.7890173410404624\n",
      "Max Depth: 4, Accuracy: 0.8439306358381503\n",
      "Max Depth: 5, Accuracy: 0.8323699421965318\n",
      "Max Depth: 6, Accuracy: 0.846820809248555\n",
      "Max Depth: 7, Accuracy: 0.846820809248555\n",
      "Max Depth: 8, Accuracy: 0.846820809248555\n",
      "Max Depth: 9, Accuracy: 0.846820809248555\n",
      "Max Depth: 10, Accuracy: 0.846820809248555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the Car Evaluation dataset\n",
    "data = pd.read_excel(\"car.xlsx\")\n",
    "\n",
    "# Car Evaluation dataset doesn't usually have missing values\n",
    "# But if it does, you can handle them similarly\n",
    "# data = data.replace(\"?\", None)\n",
    "# data = data.fillna(data.mode().iloc[0])\n",
    "\n",
    "# The Car Evaluation dataset consists of categorical features\n",
    "# We need to convert them into numerical values for processing\n",
    "categorical_columns = data.columns\n",
    "for column in categorical_columns:\n",
    "    data[column] = data[column].astype('category').cat.codes\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "# Assuming the label column is the last column in the dataset\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the max_depth values you want to evaluate\n",
    "max_depth_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Initialize a list to store the accuracy for each max_depth\n",
    "accuracies = []\n",
    "\n",
    "# Loop over the max_depth values\n",
    "for max_depth in max_depth_values:\n",
    "    classifier = ID3DecisionTreeClassifier(max_depth=max_depth)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the max_depth values and corresponding accuracies\n",
    "for max_depth, accuracy in zip(max_depth_values, accuracies):\n",
    "    print(f\"Max Depth: {max_depth}, Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Metric  the Classifier  Sklearn Classifier\n",
      "0       Accuracy        0.789017            0.742775\n",
      "1      Precision        0.756050            0.657635\n",
      "2         Recall        0.789017            0.742775\n",
      "3       F1 Score        0.770083            0.690857\n",
      "4  Training Time        0.017266            0.004052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Importing essential classes from sklearn for decision tree models and performance metrics.\n",
    "# 'DecisionTreeClassifier' is vital for constructing the tree model, \n",
    "# and various score functions are crucial for assessing its performance.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Incorporating the time module, instrumental in tracking the duration of model training.\n",
    "import time\n",
    "\n",
    "# Initializing an instance of a custom ID3DecisionTreeClassifier with a specific maximum depth.\n",
    "# Here, 'max_depth=3' is set, but it can be adjusted based on model complexity needs.\n",
    "the_classifier = ID3DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Setting up the standard DecisionTreeClassifier from sklearn.\n",
    "# This classifier is initialized with a max depth of 3 and uses 'entropy' as the splitting criterion.\n",
    "# The 'max_depth' and 'criterion' parameters are adjustable to suit different model requirements.\n",
    "sklearn_classifier = DecisionTreeClassifier(max_depth=3, criterion='entropy')\n",
    "\n",
    "# Starting the training process for the custom classifier while also keeping track of the training time.\n",
    "# This step involves fitting the model to the training data and learning from it.\n",
    "start_time = time.time()\n",
    "the_classifier.fit(X_train, y_train)\n",
    "the_training_time = time.time() - start_time\n",
    "\n",
    "# Repeating the training process for the sklearn classifier, also monitoring the time taken for training.\n",
    "# This approach enables a comparison of the training efficiency between the custom and sklearn classifiers.\n",
    "start_time = time.time()\n",
    "sklearn_classifier.fit(X_train, y_train)\n",
    "sklearn_training_time = time.time() - start_time\n",
    "\n",
    "# Generating predictions with the custom classifier for the test data set.\n",
    "# This step evaluates how well the classifier performs on data it hasn't seen during training.\n",
    "the_predictions = the_classifier.predict(X_test)\n",
    "\n",
    "# Similarly, producing predictions using the sklearn classifier for the test data set.\n",
    "sklearn_predictions = sklearn_classifier.predict(X_test)\n",
    "\n",
    "# Assessing the performance of the custom classifier using several metrics.\n",
    "# These include accuracy, precision, recall, and F1 score, providing a comprehensive evaluation.\n",
    "the_accuracy = accuracy_score(y_test, the_predictions)\n",
    "the_precision = precision_score(y_test, the_predictions, average='weighted')\n",
    "the_recall = recall_score(y_test, the_predictions, average='weighted')\n",
    "the_f1 = f1_score(y_test, the_predictions, average='weighted')\n",
    "\n",
    "# Conducting the same evaluation for the sklearn classifier, using the same set of metrics.\n",
    "# This allows for a direct comparison of the two classifiers' performances.\n",
    "sklearn_accuracy = accuracy_score(y_test, sklearn_predictions)\n",
    "sklearn_precision = precision_score(y_test, sklearn_predictions, average='weighted')\n",
    "sklearn_recall = recall_score(y_test, sklearn_predictions, average='weighted')\n",
    "sklearn_f1 = f1_score(y_test, sklearn_predictions, average='weighted')\n",
    "\n",
    "# Compiling the results into a DataFrame for an organized and comparative view.\n",
    "# This DataFrame includes all the evaluated metrics and training times for both\n",
    "\n",
    "# Compiling the results into a DataFrame for an organized and comparative view.\n",
    "# This DataFrame includes all the evaluated metrics and training times for both classifiers.\n",
    "# Such a structure is instrumental in assessing and contrasting the effectiveness of the two models.\n",
    "results = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Training Time'],\n",
    "    'the Classifier': [the_accuracy, the_precision, the_recall, the_f1, the_training_time],\n",
    "    'Sklearn Classifier': [sklearn_accuracy, sklearn_precision, sklearn_recall, sklearn_f1, sklearn_training_time]\n",
    "})\n",
    "\n",
    "# Printing the results for a quick visual inspection and comparison.\n",
    "# This output allows for an immediate assessment of how each classifier performs across different metrics.\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on the results you provided, we can observe the performance of the custom ID3Decision Tree Classifier (the_classifier) and the scikit-learn Decision Tree Classifier (Sklearn Classifier) on the Car Evaluation dataset. Let's analyze the results:\n",
    "\n",
    "Accuracy\n",
    "The custom ID3 classifier achieved a maximum accuracy of 84.68% (at depth 6-10), while for the specific depth of 3, its accuracy was 78.90%.\n",
    "The scikit-learn classifier had an accuracy of 74.28% at depth 3.\n",
    "Precision, Recall, F1 Score, and Training Time (Depth = 3)\n",
    "Precision: Measures the proportion of true positive predictions in all positive predictions. The custom ID3 classifier has higher precision (75.61%) compared to the scikit-learn classifier (65.76%).\n",
    "Recall: Also known as sensitivity, measures the proportion of actual positives that are correctly identified. The custom classifier and scikit-learn classifier have equal recall, which matches their accuracy.\n",
    "F1 Score: A harmonic mean of precision and recall. A higher F1 score indicates better performance. The custom classifier's F1 score is 77.01%, which is higher than the scikit-learn classifier's 69.09%.\n",
    "Training Time: The custom classifier took longer to train (0.007 seconds) compared to the scikit-learn classifier (0.0016 seconds).\n",
    "Interpretation\n",
    "The custom ID3 classifier generally performs better in terms of precision and F1 score at a depth of 3, which indicates a better balance between recall and precision.\n",
    "The scikit-learn classifier is faster in training, which can be an advantage in scenarios where training time is critical.\n",
    "However, the custom ID3 classifier seems to be more robust as it maintains a consistent accuracy for various depths (6-10), suggesting it might be less prone to overfitting in this scenario.\n",
    "Conclusion\n",
    "If precision and F1 score are more crucial for your application, and a slight increase in training time is acceptable, the custom ID3 classifier might be the preferred choice.\n",
    "If training time is a critical factor and you are willing to trade off some accuracy, precision, and F1 score, then the scikit-learn classifier could be more suitable.\n",
    "It's also important to consider the nature of the application and the cost of false positives and false negatives when choosing between these classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18312\\579291780.py:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, the_new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Importing the time module for tracking how long certain operations take, \n",
    "# particularly the training of machine learning models.\n",
    "import time\n",
    "\n",
    "# Initializing a DataFrame named 'results_df' with predefined columns.\n",
    "# This DataFrame is purposefully structured to store a variety of metrics and configurations \n",
    "# for performance evaluation of classifiers.\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'Classifier', 'Max_Depth', 'Training_Size', \n",
    "    'Accuracy', 'Precision', 'Recall', 'F1_Score', 'Training_Time'\n",
    "])\n",
    "\n",
    "# Defining arrays for 'max_depths' and 'training_sizes' to iterate over in the upcoming loops.\n",
    "# These arrays represent different configurations (depths of trees and sizes of training sets) \n",
    "# to evaluate the performance of the classifiers.\n",
    "max_depths = [3, 5, 10]  # Example max_depth values like 3, 5, and 10 for varying tree depths.\n",
    "training_sizes = [0.6, 0.7, 0.8]  # Example training sizes representing 60%, 70%, and 80% of the data.\n",
    "\n",
    "# Starting a nested loop: iterating over each combination of depth and training size.\n",
    "# This comprehensive approach allows for evaluating the classifiers under various scenarios.\n",
    "for depth in max_depths:\n",
    "    for size in training_sizes:\n",
    "        # Splitting the data according to the current training size, \n",
    "        # creating training and testing sets for the models.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=size, random_state=42)\n",
    "\n",
    "        # Training and evaluating the custom classifier, ID3DecisionTreeClassifier, with the specified depth.\n",
    "        # Timing the training process to assess efficiency.\n",
    "        the_classifier = ID3DecisionTreeClassifier(max_depth=depth)\n",
    "        start_time = time.time()\n",
    "        the_classifier.fit(X_train, y_train)\n",
    "        the_training_time = time.time() - start_time\n",
    "\n",
    "        # Making predictions with the custom classifier and evaluating its performance\n",
    "        # using various metrics like accuracy, precision, recall, and F1 score.\n",
    "        the_predictions = the_classifier.predict(X_test)\n",
    "        the_accuracy = accuracy_score(y_test, the_predictions)\n",
    "        the_precision = precision_score(y_test, the_predictions, average='weighted')\n",
    "        the_recall = recall_score(y_test, the_predictions, average='weighted')\n",
    "        the_f1 = f1_score(y_test, the_predictions, average='weighted')\n",
    "        # Compiling the results into a new row and adding it to the 'results_df' DataFrame.\n",
    "# This step is crucial for accumulating the performance data of the custom classifier.\n",
    "the_new_row = pd.DataFrame([['theClassifier', depth, size, the_accuracy, the_precision, the_recall, the_f1, the_training_time]], \n",
    "                           columns=results_df.columns)\n",
    "results_df = pd.concat([results_df, the_new_row], ignore_index=True)\n",
    "\n",
    "# Repeating the training and evaluation process for the sklearn DecisionTreeClassifier.\n",
    "# This classifier uses 'entropy' as the criterion for splitting and is tested for the same depth and training size.\n",
    "# Timing the training process to compare with the custom classifier's efficiency.\n",
    "sklearn_classifier = DecisionTreeClassifier(max_depth=depth, criterion='entropy')\n",
    "start_time = time.time()\n",
    "sklearn_classifier.fit(X_train, y_train)\n",
    "sklearn_training_time = time.time() - start_time\n",
    "\n",
    "# Making predictions and evaluating the sklearn classifier using the same set of metrics.\n",
    "# This step allows for direct comparison between the custom classifier and the sklearn implementation.\n",
    "sklearn_predictions = sklearn_classifier.predict(X_test)\n",
    "sklearn_accuracy = accuracy_score(y_test, sklearn_predictions)\n",
    "sklearn_precision = precision_score(y_test, sklearn_predictions, average='weighted')\n",
    "sklearn_recall = recall_score(y_test, sklearn_predictions, average='weighted')\n",
    "sklearn_f1 = f1_score(y_test, sklearn_predictions, average='weighted')\n",
    "\n",
    "# Constructing a new row for the sklearn classifier's results and appending it to 'results_df'.\n",
    "# This action helps in compiling a comprehensive set of results for later analysis.\n",
    "sklearn_new_row = pd.DataFrame([['Sklearn', depth, size, sklearn_accuracy, sklearn_precision, sklearn_recall, sklearn_f1, sklearn_training_time]], \n",
    "                               columns=results_df.columns)\n",
    "results_df = pd.concat([results_df, sklearn_new_row], ignore_index=True)\n",
    "\n",
    "# After completing all iterations and evaluations, saving the collected results into a CSV file.\n",
    "# This file 'car_comparison_results.csv' will store all performance metrics for further analysis or record-keeping.\n",
    "# The 'index=False' parameter is used to prevent pandas from adding an unnecessary index column to the CSV.\n",
    "results_df.to_csv('car_comparison_results.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Max_Depth</th>\n",
       "      <th>Training_Size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Training_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>theClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.803468</td>\n",
       "      <td>0.768683</td>\n",
       "      <td>0.803468</td>\n",
       "      <td>0.784588</td>\n",
       "      <td>0.014511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sklearn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.763006</td>\n",
       "      <td>0.682897</td>\n",
       "      <td>0.763006</td>\n",
       "      <td>0.716635</td>\n",
       "      <td>0.000988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>theClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.795761</td>\n",
       "      <td>0.739364</td>\n",
       "      <td>0.795761</td>\n",
       "      <td>0.765877</td>\n",
       "      <td>0.008976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sklearn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.757225</td>\n",
       "      <td>0.672296</td>\n",
       "      <td>0.757225</td>\n",
       "      <td>0.706765</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.789017</td>\n",
       "      <td>0.756050</td>\n",
       "      <td>0.789017</td>\n",
       "      <td>0.770083</td>\n",
       "      <td>0.012965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sklearn</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.742775</td>\n",
       "      <td>0.657635</td>\n",
       "      <td>0.742775</td>\n",
       "      <td>0.690857</td>\n",
       "      <td>0.001960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>theClassifier</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.829480</td>\n",
       "      <td>0.823136</td>\n",
       "      <td>0.829480</td>\n",
       "      <td>0.825416</td>\n",
       "      <td>0.033878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sklearn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.854046</td>\n",
       "      <td>0.840327</td>\n",
       "      <td>0.854046</td>\n",
       "      <td>0.842514</td>\n",
       "      <td>0.001960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>theClassifier</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.820809</td>\n",
       "      <td>0.819409</td>\n",
       "      <td>0.820809</td>\n",
       "      <td>0.819728</td>\n",
       "      <td>0.038932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sklearn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.863198</td>\n",
       "      <td>0.847324</td>\n",
       "      <td>0.863198</td>\n",
       "      <td>0.851329</td>\n",
       "      <td>0.001031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>theClassifier</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.832370</td>\n",
       "      <td>0.842880</td>\n",
       "      <td>0.832370</td>\n",
       "      <td>0.833865</td>\n",
       "      <td>0.041853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sklearn</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.867052</td>\n",
       "      <td>0.846424</td>\n",
       "      <td>0.867052</td>\n",
       "      <td>0.850352</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>theClassifier</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.829480</td>\n",
       "      <td>0.819350</td>\n",
       "      <td>0.829480</td>\n",
       "      <td>0.822905</td>\n",
       "      <td>0.052480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sklearn</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.963182</td>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.960806</td>\n",
       "      <td>0.000994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>theClassifier</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.828516</td>\n",
       "      <td>0.818951</td>\n",
       "      <td>0.828516</td>\n",
       "      <td>0.822969</td>\n",
       "      <td>0.049455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sklearn</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.962156</td>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.960425</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>theClassifier</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.846821</td>\n",
       "      <td>0.848196</td>\n",
       "      <td>0.846821</td>\n",
       "      <td>0.845835</td>\n",
       "      <td>0.053403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sklearn</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.953757</td>\n",
       "      <td>0.971473</td>\n",
       "      <td>0.953757</td>\n",
       "      <td>0.957909</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classifier Max_Depth  Training_Size  Accuracy  Precision    Recall  \\\n",
       "0   theClassifier         3            0.6  0.803468   0.768683  0.803468   \n",
       "1         Sklearn         3            0.6  0.763006   0.682897  0.763006   \n",
       "2   theClassifier         3            0.7  0.795761   0.739364  0.795761   \n",
       "3         Sklearn         3            0.7  0.757225   0.672296  0.757225   \n",
       "4   theClassifier         3            0.8  0.789017   0.756050  0.789017   \n",
       "5         Sklearn         3            0.8  0.742775   0.657635  0.742775   \n",
       "6   theClassifier         5            0.6  0.829480   0.823136  0.829480   \n",
       "7         Sklearn         5            0.6  0.854046   0.840327  0.854046   \n",
       "8   theClassifier         5            0.7  0.820809   0.819409  0.820809   \n",
       "9         Sklearn         5            0.7  0.863198   0.847324  0.863198   \n",
       "10  theClassifier         5            0.8  0.832370   0.842880  0.832370   \n",
       "11        Sklearn         5            0.8  0.867052   0.846424  0.867052   \n",
       "12  theClassifier        10            0.6  0.829480   0.819350  0.829480   \n",
       "13        Sklearn        10            0.6  0.959538   0.963182  0.959538   \n",
       "14  theClassifier        10            0.7  0.828516   0.818951  0.828516   \n",
       "15        Sklearn        10            0.7  0.959538   0.962156  0.959538   \n",
       "16  theClassifier        10            0.8  0.846821   0.848196  0.846821   \n",
       "17        Sklearn        10            0.8  0.953757   0.971473  0.953757   \n",
       "\n",
       "    F1_Score  Training_Time  \n",
       "0   0.784588       0.014511  \n",
       "1   0.716635       0.000988  \n",
       "2   0.765877       0.008976  \n",
       "3   0.706765       0.000997  \n",
       "4   0.770083       0.012965  \n",
       "5   0.690857       0.001960  \n",
       "6   0.825416       0.033878  \n",
       "7   0.842514       0.001960  \n",
       "8   0.819728       0.038932  \n",
       "9   0.851329       0.001031  \n",
       "10  0.833865       0.041853  \n",
       "11  0.850352       0.000996  \n",
       "12  0.822905       0.052480  \n",
       "13  0.960806       0.000994  \n",
       "14  0.822969       0.049455  \n",
       "15  0.960425       0.000997  \n",
       "16  0.845835       0.053403  \n",
       "17  0.957909       0.000997  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
